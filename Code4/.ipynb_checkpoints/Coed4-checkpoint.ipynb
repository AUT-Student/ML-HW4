{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/zhpinkman/armed-bandit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ./armed-bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impor Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mBMoPLmGbrIn"
   },
   "outputs": [],
   "source": [
    "from amalearn.reward import RewardBase\n",
    "from amalearn.agent import AgentBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YBACGmh0brIr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from amalearn.environment import EnvironmentBase\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "pH6sNHxPbrIs"
   },
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "# Action:\n",
    "# 0 1 2\n",
    "# 3 4 5\n",
    "# 6 7 8\n",
    "\n",
    "class Environment(EnvironmentBase):\n",
    "    def __init__(self, obstacle = [] ,id = 0, action_count=9, actionPrice = -1, goalReward = 100\n",
    "                 , punish=-10, j_limit = 10, i_limit = 10, p = 0.8, container=None):\n",
    "        \"\"\"\n",
    "        initialize your variables\n",
    "        \"\"\"\n",
    "        \n",
    "        self.obstacle = obstacle\n",
    "        \n",
    "        self.x_min = 1\n",
    "        self.x_max = i_limit\n",
    "        \n",
    "        self.y_min = 1\n",
    "        self.y_max = j_limit\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "        self.action_count = action_count\n",
    "        self.actionPrice = actionPrice\n",
    "        self.goalReward = goalReward\n",
    "        self.punish = punish\n",
    "        self.p = p\n",
    "        \n",
    "        action_space = Discrete(action_count)\n",
    "        state_space = Box(low=1, high=max(i_limit, j_limit), shape=(1,2), dtype=int)\n",
    "        \n",
    "        self.action_list = list(range(1,10))\n",
    "        self.state_list = []\n",
    "        \n",
    "        for i in range(1, i_limit+1):\n",
    "            for j in range(1, j_limit+1):\n",
    "                self.state_list.append(np.array([i, j]))\n",
    "        \n",
    "        super(Environment, self).__init__(action_space=action_space, state_space=state_space, id=id ,container=container)\n",
    "\n",
    "        \n",
    "    def isStatePossible(self, state):\n",
    "        \"\"\"if given state is possible (not out of the grid and not obstacle) return ture\"\"\"\n",
    "        if self.x_min <= state[0] <= self.x_max and self.y_min <= state[1] <= self.y_max:\n",
    "            for obstacle_item in self.obstacle:\n",
    "                if (state==obstacle_item).all():\n",
    "                    return False\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    \n",
    "    def isAccessible(self, state, state_p):\n",
    "        \"\"\"if given state is Accesible (we can reach state_p by doing an action from state) return true\"\"\"\n",
    "        return abs(state[0]-state_p[0]) <= 1 and abs(state[1] - state_p[1]) <= 1 and self.isStatePossible(state_p)\n",
    "            \n",
    "    def getTransitionStatesAndProbs(self, state, action, state_p):\n",
    "        \"\"\"return probability of transition or T(sp,a,s)\"\"\"\n",
    "        \n",
    "        actions = self.available_actions_state(state)\n",
    "        \n",
    "        if (self.calculate_next_state(state,action)==state_p).all():\n",
    "            if self.isAccessible(state, state_p):\n",
    "                return self.p + (1-self.p) / len(actions)\n",
    "            else:\n",
    "                return self.p\n",
    "        else:\n",
    "            if self.isAccessible(state, state_p):\n",
    "                return (1-self.p) / len(actions)\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "    \n",
    "    def getReward(self, state, action, state_p):\n",
    "        \"\"\"return reward of transition\"\"\"\n",
    "        if self.terminated_state(state_p):\n",
    "            return self.actionPrice + self.goalReward\n",
    "        \n",
    "        if self.isStatePossible(state_p):\n",
    "            return self.actionPrice\n",
    "        else:\n",
    "            return self.actionPrice + self.punish\n",
    "        \n",
    "    def sample_all_rewards(self):\n",
    "        return \n",
    "    \n",
    "    def calculate_reward(self, action):\n",
    "        # ????\n",
    "        return self.getReward(self.current_state, action, self.calculate_next_state(self.current_state, action))\n",
    "\n",
    "    def available_states_state(self, state):\n",
    "        states = []\n",
    "        for i in [-1, 0, +1]:\n",
    "            for j in [-1, 0, +1]:\n",
    "                new_state = np.array([state[0]+i, state[1]+j])\n",
    "                \n",
    "                if self.isAccessible(state, new_state):\n",
    "                    states.append(new_state)\n",
    "        return states\n",
    "    \n",
    "    def terminated(self):\n",
    "        return self.terminated_state(self.current_state)\n",
    "    \n",
    "    def terminated_state(self, state):\n",
    "        return (state==np.array([1,1])).all()\n",
    "        \n",
    "    def observe(self):\n",
    "        return self.current_state \n",
    "\n",
    "    def available_actions(self):\n",
    "        return self.available_actions_state(self.current_state)\n",
    "    \n",
    "    def available_actions_state(self, state):\n",
    "        output_actions = []\n",
    "        for action in range(self.action_count):\n",
    "            next_state = self.calculate_next_state(state, action)\n",
    "            \n",
    "            if self.isAccessible(state, next_state):\n",
    "                output_actions.append(action)\n",
    "        \n",
    "        return output_actions\n",
    "        \n",
    "    \n",
    "    def calculate_next_state(self, state, action):\n",
    "        return np.array([state[0] + (action%3 -1), state[1] + (int(action/3)-1) ])\n",
    "        \n",
    "    def next_state(self, action):\n",
    "        actions = self.available_actions()\n",
    "        \n",
    "        if action not in actions:\n",
    "            actions.append(action)\n",
    "                \n",
    "        probabilities = []\n",
    "                \n",
    "        for action2 in actions:\n",
    "            state2 = self.calculate_next_state(self.current_state, action2)\n",
    "            probabilities.append(self.getTransitionStatesAndProbs(self.current_state, action, state2))\n",
    "        \n",
    "        final_action = random.choices(population=actions, weights=probabilities, k=1)[0]\n",
    "        \n",
    "        real_next_state = self.calculate_next_state(self.current_state, final_action)\n",
    "        \n",
    "        if not self.isStatePossible(real_next_state):\n",
    "            real_next_state = self.current_state\n",
    "        \n",
    "        self.last_action = action\n",
    "        \n",
    "        self.sliped = not (final_action==action)\n",
    "        \n",
    "        self.current_state = real_next_state\n",
    "        \n",
    "        return\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state = np.array([15, 15])\n",
    "        \n",
    "        self.last_action = None\n",
    "        self.sliped = None\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"{self.current_state} \\t {self.last_action} \\t {self.sliped}\")\n",
    "        return \n",
    "\n",
    "    def close(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_states =  [np.array([7, 1]), np.array([8, 1]), np.array([7, 2]), np.array([8, 2])\n",
    "                ,np.array([7, 3]), np.array([8, 3]), np.array([7, 4]), np.array([8, 4])\n",
    "                ,np.array([13, 8]), np.array([14, 8]), np.array([15, 8])\n",
    "                ,np.array([13, 9]), np.array([14, 9]), np.array([15, 9])\n",
    "                ,np.array([6, 12]), np.array([7, 12]), np.array([6, 13]), np.array([7, 13])\n",
    "                ,np.array([6, 14]), np.array([7, 14]), np.array([6, 15]), np.array([7, 15])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_environment = Environment(obstacle = grid_states ,id = 0, action_count=9, actionPrice = -1, goalReward = 100\n",
    "                                , punish=-10, j_limit = 15, i_limit = 15, p = 0.8, container=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "id": "898Jlhsycyes"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Agent(AgentBase):\n",
    "    def __init__(self, id, environment, discount, theta):\n",
    "        \n",
    "        # initialize a random policy and V(s) = 0 for each state\n",
    "        self.environment = environment\n",
    "        \n",
    "        # mapp states to its ids\n",
    "#         self.mapp = {}\n",
    "        \n",
    "        # init V\n",
    "        self.V = {}\n",
    "        \n",
    "        # init policy\n",
    "        self.policy = {}\n",
    "        \n",
    "        super(Agent, self).__init__(id, environment)\n",
    "        \n",
    "        self.discount = discount\n",
    "        \n",
    "        self.theta = theta\n",
    "                \n",
    "        self.value_initialization()\n",
    "        \n",
    "        self.policy_initialization()\n",
    "    \n",
    "    def value_initialization(self):\n",
    "        for state in self.environment.state_list:\n",
    "            self.V[tuple(state)] = 0\n",
    "        \n",
    "    def policy_initialization(self):\n",
    "        for state in self.environment.state_list:\n",
    "            self.policy[tuple(state)] = random.choice(self.environment.action_list)\n",
    "        \n",
    "    def policy_evaluation(self):\n",
    "        pass\n",
    "    \n",
    "    def policy_improvement(self):\n",
    "        pass\n",
    "    \n",
    "    def value_iteration(self):\n",
    "        for iter in range(self.theta[\"max_iter\"]):\n",
    "            new_V = {}\n",
    "\n",
    "            delta = 0\n",
    "            for state in self.environment.state_list:\n",
    "                new_V[tuple(state)] = -math.inf\n",
    "\n",
    "                available_actions = self.environment.available_actions_state(state)\n",
    "                available_states  = self.environment.available_states_state(state)\n",
    "\n",
    "                for action in available_actions:\n",
    "                    sum = 0\n",
    "                    for state_p in available_states:\n",
    "                        p_sp = self.environment.getTransitionStatesAndProbs(state, action, state_p)\n",
    "                        r_sp = self.environment.getReward(state, action, state_p)\n",
    "                        v_sp = self.V[tuple(state_p)]\n",
    "\n",
    "                        sum += p_sp * (r_sp + self.discount * v_sp)\n",
    "\n",
    "                    new_V[tuple(state)] = max(new_V[tuple(state)], sum)\n",
    "                delta = max(delta, abs(self.V[tuple(state)] - new_V[tuple(state)]))\n",
    "                \n",
    "            print(f\"iter = {iter} -> delta = {round(delta, 2)}\")\n",
    "            self.V = deepcopy(new_V)\n",
    "\n",
    "            if delta < self.theta[\"delta_treshold\"]:\n",
    "                break\n",
    "    \n",
    "    def policy_extraction(self):\n",
    "        for state in self.environment.state_list:\n",
    "\n",
    "            available_actions = self.environment.available_actions_state(state)\n",
    "            available_states  = self.environment.available_states_state(state)\n",
    "            \n",
    "            max_value = -math.inf\n",
    "            argmax = None\n",
    "            \n",
    "            for action in available_actions:\n",
    "                sum = 0\n",
    "                for state_p in available_states:\n",
    "                    p_sp = self.environment.getTransitionStatesAndProbs(state, action, state_p)\n",
    "                    v_sp = self.V[tuple(state_p)]\n",
    "\n",
    "                    sum += p_sp * v_sp\n",
    "            \n",
    "                if sum > max_value:\n",
    "                    max_value = sum\n",
    "                    argmax = action\n",
    "                    \n",
    "            self.policy[tuple(state)] = action\n",
    "    \n",
    "    def take_action(self) -> (object, float, bool, object):\n",
    "        # in this method, you MUST call the `step` method of \n",
    "        # the environment and observe the results and return them like:\n",
    "        # return observation, reward, done, info\n",
    "\n",
    "        return self.environment.step(random.choice(self.environment.action_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = {\"max_iter\": 50, \"delta_treshold\": 5}\n",
    "agent = Agent(id=0, environment=base_environment, discount=0.9, theta=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0 -> delta = 84.0\n",
      "iter = 1 -> delta = 75.33\n",
      "iter = 2 -> delta = 66.97\n",
      "iter = 3 -> delta = 60.19\n",
      "iter = 4 -> delta = 54.09\n",
      "iter = 5 -> delta = 48.66\n",
      "iter = 6 -> delta = 43.79\n",
      "iter = 7 -> delta = 39.4\n",
      "iter = 8 -> delta = 35.46\n",
      "iter = 9 -> delta = 31.91\n",
      "iter = 10 -> delta = 28.72\n",
      "iter = 11 -> delta = 25.85\n",
      "iter = 12 -> delta = 23.27\n",
      "iter = 13 -> delta = 20.94\n",
      "iter = 14 -> delta = 18.84\n",
      "iter = 15 -> delta = 16.96\n",
      "iter = 16 -> delta = 15.26\n",
      "iter = 17 -> delta = 13.74\n",
      "iter = 18 -> delta = 12.36\n"
     ]
    }
   ],
   "source": [
    "agent.value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): 783.9155422874419,\n",
       " (1, 2): 776.1130222384076,\n",
       " (1, 3): 675.5964143085928,\n",
       " (1, 4): 587.4156017903489,\n",
       " (1, 5): 509.9722184592374,\n",
       " (1, 6): 441.90112249481996,\n",
       " (1, 7): 382.06205314433134,\n",
       " (1, 8): 329.4571692165742,\n",
       " (1, 9): 283.21153521371934,\n",
       " (1, 10): 242.5565609249047,\n",
       " (1, 11): 206.81851816900988,\n",
       " (1, 12): 175.41130262397598,\n",
       " (1, 13): 147.8571019588321,\n",
       " (1, 14): 123.86239029998966,\n",
       " (1, 15): 104.83683889975019,\n",
       " (2, 1): 776.1131327094422,\n",
       " (2, 2): 770.691043432773,\n",
       " (2, 3): 673.2915099283804,\n",
       " (2, 4): 587.0977343679854,\n",
       " (2, 5): 509.87001958279984,\n",
       " (2, 6): 441.8801882717566,\n",
       " (2, 7): 382.0559397614018,\n",
       " (2, 8): 329.4556876780628,\n",
       " (2, 9): 283.2111789434834,\n",
       " (2, 10): 242.55710782236736,\n",
       " (2, 11): 206.82256274224576,\n",
       " (2, 12): 175.44633833729895,\n",
       " (2, 13): 147.97019706308708,\n",
       " (2, 14): 124.31517748394447,\n",
       " (2, 15): 105.58355388011623,\n",
       " (3, 1): 675.5983490219983,\n",
       " (3, 2): 673.2932575948626,\n",
       " (3, 3): 663.4253411001391,\n",
       " (3, 4): 583.1388453176338,\n",
       " (3, 5): 509.1641916717175,\n",
       " (3, 6): 441.6554616603557,\n",
       " (3, 7): 382.00440636262215,\n",
       " (3, 8): 329.44054313286745,\n",
       " (3, 9): 283.20775577526655,\n",
       " (3, 10): 242.55850900305873,\n",
       " (3, 11): 206.84982271412807,\n",
       " (3, 12): 175.5497406331255,\n",
       " (3, 13): 148.5343208483508,\n",
       " (3, 14): 125.28110532594026,\n",
       " (3, 15): 105.73229932013624,\n",
       " (4, 1): 587.4453511213906,\n",
       " (4, 2): 587.1260314325,\n",
       " (4, 3): 583.1621602422421,\n",
       " (4, 4): 570.719642186961,\n",
       " (4, 5): 504.13453722460076,\n",
       " (4, 6): 440.58659489958194,\n",
       " (4, 7): 381.65709087036754,\n",
       " (4, 8): 329.35362116245085,\n",
       " (4, 9): 283.182900619732,\n",
       " (4, 10): 242.57092492695423,\n",
       " (4, 11): 206.91570230774042,\n",
       " (4, 12): 176.21597425611745,\n",
       " (4, 13): 149.75452729271018,\n",
       " (4, 14): 125.3845452216773,\n",
       " (4, 15): 105.79220893648946,\n",
       " (5, 1): 510.41633072579606,\n",
       " (5, 2): 510.3093903932777,\n",
       " (5, 3): 509.54086932148306,\n",
       " (5, 4): 504.391274999421,\n",
       " (5, 5): 490.54904050738344,\n",
       " (5, 6): 434.9449097736115,\n",
       " (5, 7): 380.2786636410671,\n",
       " (5, 8): 328.89262531086484,\n",
       " (5, 9): 283.0606218243961,\n",
       " (5, 10): 242.57318058881575,\n",
       " (5, 11): 207.70112960868647,\n",
       " (5, 12): 177.7647759421772,\n",
       " (5, 13): 149.81065455596172,\n",
       " (5, 14): 125.41311295313214,\n",
       " (5, 15): 105.79761655390392,\n",
       " (6, 1): 448.4831235490526,\n",
       " (6, 2): 448.44641898099985,\n",
       " (6, 3): 448.06327686401994,\n",
       " (6, 4): 444.3033430528557,\n",
       " (6, 5): 436.41790847165163,\n",
       " (6, 6): 421.05372236254266,\n",
       " (6, 7): 374.3357306978883,\n",
       " (6, 8): 327.2687979212566,\n",
       " (6, 9): 282.5017407169313,\n",
       " (6, 10): 242.45152833462808,\n",
       " (6, 11): 208.67046026252984,\n",
       " (6, 12): 179.21930838742617,\n",
       " (6, 13): 149.85965664430503,\n",
       " (6, 14): 125.41581532331166,\n",
       " (6, 15): 105.79914484702638,\n",
       " (7, 1): 398.3203864015185,\n",
       " (7, 2): 398.29629673869545,\n",
       " (7, 3): 398.01908263241694,\n",
       " (7, 4): 390.85304620277935,\n",
       " (7, 5): 384.59689491957744,\n",
       " (7, 6): 375.62342510402124,\n",
       " (7, 7): 360.6764063210102,\n",
       " (7, 8): 321.2514840172648,\n",
       " (7, 9): 280.697724578914,\n",
       " (7, 10): 241.81003249956402,\n",
       " (7, 11): 208.48125449250185,\n",
       " (7, 12): 179.16487020848487,\n",
       " (7, 13): 149.60060223575047,\n",
       " (7, 14): 125.16536207474184,\n",
       " (7, 15): 105.5736681047724,\n",
       " (8, 1): 174.9377747680776,\n",
       " (8, 2): 203.17765009559258,\n",
       " (8, 3): 239.44891808912752,\n",
       " (8, 4): 326.16212623109146,\n",
       " (8, 5): 329.91323779821874,\n",
       " (8, 6): 330.6873568105287,\n",
       " (8, 7): 322.3778761139312,\n",
       " (8, 8): 308.16745974113473,\n",
       " (8, 9): 274.7664300274432,\n",
       " (8, 10): 239.8494833128915,\n",
       " (8, 11): 206.76392932273038,\n",
       " (8, 12): 177.47399207967175,\n",
       " (8, 13): 149.52645884104265,\n",
       " (8, 14): 125.15989617334755,\n",
       " (8, 15): 105.57098168247853,\n",
       " (9, 1): 174.8962925380418,\n",
       " (9, 2): 203.09614988491256,\n",
       " (9, 3): 238.2167357301564,\n",
       " (9, 4): 279.8476949416552,\n",
       " (9, 5): 283.077490975885,\n",
       " (9, 6): 284.04352521506075,\n",
       " (9, 7): 283.4392922199373,\n",
       " (9, 8): 275.73949592863545,\n",
       " (9, 9): 262.4618171141288,\n",
       " (9, 10): 234.07919278777334,\n",
       " (9, 11): 203.9996694408822,\n",
       " (9, 12): 175.17349769906627,\n",
       " (9, 13): 149.40394427807848,\n",
       " (9, 14): 125.11134036509361,\n",
       " (9, 15): 105.5598184514117,\n",
       " (10, 1): 174.7340696687606,\n",
       " (10, 2): 202.33652124955017,\n",
       " (10, 3): 236.42187065475602,\n",
       " (10, 4): 241.32935085726368,\n",
       " (10, 5): 243.1316439300848,\n",
       " (10, 6): 243.24527985071379,\n",
       " (10, 7): 243.07110915032175,\n",
       " (10, 8): 242.0037506699283,\n",
       " (10, 9): 234.89921559417863,\n",
       " (10, 10): 222.6500665140772,\n",
       " (10, 11): 198.45130660253102,\n",
       " (10, 12): 172.50958521562262,\n",
       " (10, 13): 147.4093322895208,\n",
       " (10, 14): 124.879510709408,\n",
       " (10, 15): 105.44926039124692,\n",
       " (11, 1): 173.0768508656007,\n",
       " (11, 2): 199.04706247771313,\n",
       " (11, 3): 204.74512947649316,\n",
       " (11, 4): 207.08825249682812,\n",
       " (11, 5): 207.3732299357558,\n",
       " (11, 6): 207.43269718549936,\n",
       " (11, 7): 207.43674663798316,\n",
       " (11, 8): 207.1305879430265,\n",
       " (11, 9): 205.74483894067598,\n",
       " (11, 10): 199.18323413680733,\n",
       " (11, 11): 187.96015139345772,\n",
       " (11, 12): 167.2547200285396,\n",
       " (11, 13): 144.86470880190802,\n",
       " (11, 14): 123.12362331982914,\n",
       " (11, 15): 105.08628356033904,\n",
       " (12, 1): 168.1885422146129,\n",
       " (12, 2): 172.79311350411498,\n",
       " (12, 3): 175.36751335027554,\n",
       " (12, 4): 175.8192974521049,\n",
       " (12, 5): 175.9465688780819,\n",
       " (12, 6): 176.0148076839145,\n",
       " (12, 7): 176.70253668163554,\n",
       " (12, 8): 177.5197074347416,\n",
       " (12, 9): 177.01099681905225,\n",
       " (12, 10): 174.51415702923504,\n",
       " (12, 11): 167.92386505031175,\n",
       " (12, 12): 157.70119445516974,\n",
       " (12, 13): 139.94523580997847,\n",
       " (12, 14): 120.70569904628225,\n",
       " (12, 15): 103.42640576517894,\n",
       " (13, 1): 145.53905270647914,\n",
       " (13, 2): 147.5297690315716,\n",
       " (13, 3): 148.0783066675901,\n",
       " (13, 4): 148.2673656670057,\n",
       " (13, 5): 148.38118443831527,\n",
       " (13, 6): 148.96676016792134,\n",
       " (13, 7): 150.3024193724138,\n",
       " (13, 8): 151.56782519218453,\n",
       " (13, 9): 151.43465070887854,\n",
       " (13, 10): 149.53340607312836,\n",
       " (13, 11): 146.51391725147727,\n",
       " (13, 12): 140.5454487252809,\n",
       " (13, 13): 131.3055955621907,\n",
       " (13, 14): 116.13672062471488,\n",
       " (13, 15): 100.99077562497075,\n",
       " (14, 1): 123.38922355176675,\n",
       " (14, 2): 123.82861614447313,\n",
       " (14, 3): 124.050567433289,\n",
       " (14, 4): 124.1954686016655,\n",
       " (14, 5): 124.69665297280058,\n",
       " (14, 6): 125.75101471221046,\n",
       " (14, 7): 125.80028678921451,\n",
       " (14, 8): 125.84291791643429,\n",
       " (14, 9): 125.15830857966922,\n",
       " (14, 10): 125.05808738910001,\n",
       " (14, 11): 124.83969445920776,\n",
       " (14, 12): 122.06662604608474,\n",
       " (14, 13): 116.66761232901784,\n",
       " (14, 14): 108.42733993931763,\n",
       " (14, 15): 96.60222540360193,\n",
       " (15, 1): 104.37660275582716,\n",
       " (15, 2): 104.55676409272473,\n",
       " (15, 3): 104.70794697793062,\n",
       " (15, 4): 105.1376172869976,\n",
       " (15, 5): 105.98937228841362,\n",
       " (15, 6): 106.10299414385794,\n",
       " (15, 7): 106.13930550634306,\n",
       " (15, 8): 106.14315473896075,\n",
       " (15, 9): 105.4816519169457,\n",
       " (15, 10): 105.46718315956335,\n",
       " (15, 11): 105.3639185482616,\n",
       " (15, 12): 104.85460664460345,\n",
       " (15, 13): 102.11648283479747,\n",
       " (15, 14): 97.03386390421514,\n",
       " (15, 15): 90.4268751923221}"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.imshow(np.random.random((50,50)))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "env.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "83fad98a7911d3a2a55c2e5234aea09e74d0252d0d10d90172c6e09f21426bdf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
